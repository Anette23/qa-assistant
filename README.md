# ğŸ§ª QA Assistant â€” AI-Powered Testing Toolkit

> A complete, single-page web app that guides you through the full QA workflow â€” from test planning to execution tracking â€” powered by Claude AI.

## âœ¨ Features

The app follows a real QA workflow â€” each tab represents a phase you'd go through in an actual testing cycle:

| Step | Tool | Description |
|------|------|-------------|
| 1 | ğŸ—ºï¸ **Test Plan** | Generate a full test plan with scope, phases, risks and entry/exit criteria |
| 2 | ğŸ§ª **Test Cases** | Generate structured test cases (functional, negative, boundary, smoke, regression) |
| 3 | âœ… **Acceptance Criteria** | Generate Gherkin (Given/When/Then) scenarios and checklists from user stories |
| 4 | â–¶ï¸ **Test Execution** | Run tests, mark each as Pass / Fail / Blocked / Skipped, track progress live |
| 5 | ğŸ› **Bug Report** | Create structured bug reports â€” auto-prefilled from failed test cases |
| 6 | ğŸ“‹ **Test Notes** | Turn raw notes into professional Test Summary Reports or Session Notes |
| 7 | ğŸ” **Review** | Score and review existing test cases or bug reports with AI feedback |

---

## ğŸš€ Live Demo

**[â†’ Open QA Assistant](https://anette23.github.io/qa-assistant/)**

---

## â–¶ï¸ Test Execution â€” Highlight Feature

The Execution tab works like a lightweight TestRail:

- AI generates test cases based on the feature you describe
- Each test case shows steps, preconditions and expected result
- Mark each test as **âœ“ Pass**, **âœ— Fail**, **â›” Blocked** or **â­ Skipped**
- Add notes to individual test cases
- When a test **Fails**, a button appears to instantly pre-fill a Bug Report
- Live stats bar tracks Pass / Fail / Blocked / Skipped counts
- Progress bar shows how far through the execution you are
- Click **"Generate Summary"** to get an AI-written Execution Summary report
- **Session is saved to localStorage** â€” results persist after page refresh

---

## ğŸ› ï¸ How to Use

1. **Open the app** â€” no installation needed, runs entirely in the browser
2. **Follow the workflow** â€” start with Test Plan, work through each step
3. **Copy & paste outputs** â€” use results directly in Jira, Confluence, Notion or any tool

---

## ğŸ’¡ Example Workflow

1. **Test Plan** â†’ describe your project, get a full test plan with phases and risks
2. **Test Cases** â†’ describe the login feature, get 5 structured test cases
3. **Acceptance Criteria** â†’ paste a user story, get Gherkin scenarios + checklist
4. **Execution** â†’ AI generates test cases, you click Pass/Fail as you test
5. **Bug Report** â†’ a test fails â†’ click "Create Bug Report" â†’ form auto-fills
6. **Test Notes** â†’ paste your observations, get a clean Test Summary Report
7. **Review** â†’ paste a test case, get a score + improvement suggestions

---

## âš™ï¸ Tech Stack

- **Pure HTML / CSS / JavaScript** â€” no frameworks, no build tools, no dependencies
- **Anthropic Claude API** â€” `claude-sonnet-4-20250514` model
- **Cloudflare Workers** â€” secure API proxy, no API key needed from the user
- **localStorage** â€” execution sessions persist across page refreshes
- **3 files** â€” easy to deploy anywhere

---

## ğŸ“ Project Structure

```
qa-assistant/
â”œâ”€â”€ index.html    # App structure and layout
â”œâ”€â”€ style.css     # All styling and themes
â”œâ”€â”€ app.js        # Logic, AI calls, execution tracking
â””â”€â”€ README.md     # This file
```

---

## ğŸŒ± Future Ideas

- [ ] Export execution results to PDF or CSV
- [ ] Multiple execution sessions with history
- [ ] Jira integration â€” create issues directly from bug reports
- [ ] Custom templates per team or project
- [ ] Dark / light theme toggle

---

## ğŸ‘©â€ğŸ’» About

Built as a portfolio project to demonstrate practical AI integration in a real QA workflow.  
Created with [Claude AI](https://claude.ai) Â· Deployed via GitHub Pages

---

*Feel free to fork, use, and adapt for your own QA workflow!*
